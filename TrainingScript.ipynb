{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "370d6f0e-c317-4617-be0e-f392c73c3f7b",
   "metadata": {},
   "source": [
    "# Training Script\n",
    "Adapted from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e6dc8d-b45b-47d4-95a5-62be301f8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Literal, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83369112-bde9-4a94-abac-501235a00048",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227ddc86-69ce-4b93-9381-0d49b603f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e59651-6c89-461a-8341-cab4b0009519",
   "metadata": {},
   "source": [
    "### Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5951653b-7bb7-4cb1-a6f9-41a7d8066390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c0cc9b-899f-474c-b653-4ac560b35948",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "256aadda-267c-4612-8edd-fe5248a4ad3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "def load_model(model_name: str, n_classes: int) -> Tuple[nn.Module, int]:\n",
    "    if model_name == \"resnet\":\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        n_features_in = model.fc.in_features\n",
    "        model.fc = nn.Linear(n_features_in, 10)\n",
    "    elif model_name == \"mobilenet\":\n",
    "        model = models.mobilenet.mobilenet_v3_small(pretrained=True)\n",
    "        n_features_in = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(n_features_in, n_classes)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    input_size = 224\n",
    "    return model, input_size\n",
    "\n",
    "model, input_size = load_model('mobilenet', n_classes=10)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd844f9f-8c4a-4c05-b79f-ce3e13f97e65",
   "metadata": {},
   "source": [
    "### Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef4f6b5-7e23-461f-9670-55ee5e475f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T\n",
    "\n",
    "train_transform = T.Compose(\n",
    "    [\n",
    "        T.Resize((input_size, input_size)),\n",
    "        T.RandomAffine(10, translate=(0.02, 0.02), scale=(0.9, 1.1)),\n",
    "        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "non_train_transform = T.Compose([T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a50d6-1754-4aac-b243-aee26ad291c3",
   "metadata": {},
   "source": [
    "### MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57021528-5ef8-4ada-b219-025d1c77df9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 50000\n",
      "Number of validation examples: 10000\n",
      "Number of test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, set: Union[Literal[\"train\"], Literal[\"val\"], Literal[\"test\"]]):\n",
    "        DATA_DIR = Path(\"data/MNIST\")\n",
    "        self.images = torch.concat(\n",
    "            [torch.load(DATA_DIR / f\"{set}_images.pt\")] * 3, dim=1\n",
    "        )\n",
    "        self.labels = torch.load(DATA_DIR / f\"{set}_labels.pt\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.images[index], self.labels[index]\n",
    "\n",
    "\n",
    "train_dataset = MNISTDataset(\"train\")\n",
    "val_dataset = MNISTDataset(\"val\")\n",
    "test_dataset = MNISTDataset(\"test\")\n",
    "\n",
    "print(f\"Number of training examples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation examples: {len(val_dataset)}\")\n",
    "print(f\"Number of test examples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf9de31-db5f-44d2-87d3-0be72a0938c6",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f471f9cd-7596-4845-a5fd-e92188f28507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE * 2, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE * 2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a948b8-ad1b-44ce-9e08-31f87778c24e",
   "metadata": {},
   "source": [
    "### Criterion & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bec2bb9-76fa-49ea-9805-c32e16c327cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e3054-2541-4cd4-8a1f-4ac6ad8b4ea9",
   "metadata": {},
   "source": [
    "### Training & Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d1f422c-c10f-4a80-a1e3-be452a2dc22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.001\n",
      "[1,   101] loss: 0.018\n",
      "[1,   201] loss: 0.006\n",
      "[1,   301] loss: 0.005\n",
      "[1,   401] loss: 0.004\n",
      "[1,   501] loss: 0.004\n",
      "[1,   601] loss: 0.003\n",
      "[1,   701] loss: 0.003\n",
      "[1,   801] loss: 0.005\n",
      "[1,   901] loss: 0.003\n",
      "[1,  1001] loss: 0.003\n",
      "[1,  1101] loss: 0.003\n",
      "[1,  1201] loss: 0.002\n",
      "[1,  1301] loss: 0.003\n",
      "[1,  1401] loss: 0.003\n",
      "[1,  1501] loss: 0.003\n",
      "Training job completed in : 143.4s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def evaluate(model: nn.Module, dataloader: DataLoader) -> None:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (X, y) in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            X = non_train_transform(X)\n",
    "            y_pred = model(X)\n",
    "\n",
    "            _, y_pred = torch.max(y_pred.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (y_pred == y).sum().item()\n",
    "\n",
    "    print(\n",
    "        \"Accuracy of the network on the images: %d %%\"\n",
    "        % (100 * correct / total)\n",
    "    )\n",
    "\n",
    "start = time.perf_counter()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for train_idx, (X_train, y_train) in enumerate(train_dataloader):\n",
    "        X_train = X_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass + loss calc + backprop + update model params\n",
    "        X_train = train_transform(X_train)\n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if train_idx % 100 == 0:\n",
    "            print(\n",
    "                \"[%d, %5d] loss: %.3f\" % (epoch + 1, train_idx + 1, running_loss / 2000)\n",
    "            )\n",
    "            running_loss = 0.0\n",
    "\n",
    "evaluate(model, test_dataloader)\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f\"Training job completed in : {end - start:.1f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
